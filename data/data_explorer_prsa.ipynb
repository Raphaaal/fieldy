{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import dataset\n",
    "import torch\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from  sklearn.manifold import TSNE\n",
    "from  sklearn.decomposition import PCA\n",
    "from  sklearn.preprocessing import KBinsDiscretizer\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from  sklearn.preprocessing import RobustScaler\n",
    "from  sklearn.preprocessing import StandardScaler\n",
    "from  sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.option_context('display.max_rows', None, 'display.max_columns', None,'display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"prsa\"\n",
    "name_suffix = \"\"\n",
    "# name_suffix = \"timedelta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"prsa\":\n",
    "    with open(f\"../data/prsa/PRSADataset_labeled{name_suffix}.pkl\", \"rb\") as f:\n",
    "        dataset = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI: Stations order when the dataset samples were preprared\n",
    "stations = []\n",
    "for group in dataset.data.groupby(\"station\"):\n",
    "    station_name = group[0]\n",
    "    stations.append(station_name)\n",
    "print(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI: raw initial data\n",
    "os.chdir(\"..\")\n",
    "raw_data = dataset.read_data(dataset.data_root, dataset.nrows)\n",
    "raw_data[\"timestamp_raw\"] = pd.to_datetime(dict(year=raw_data['year'], month=raw_data['month'], day=raw_data['day'], hour=raw_data['hour'])).astype(int)\n",
    "raw_data[\"date_raw\"] = pd.to_datetime(dict(year=raw_data['year'], month=raw_data['month'], day=raw_data['day'], hour=raw_data['hour']))\n",
    "raw_data['year_month'] = raw_data['date_raw'].dt.strftime('%Y-%m')\n",
    "raw_data['weekday'] = raw_data['date_raw'].dt.dayofweek\n",
    "raw_data = raw_data.sort_values(by=[\"station\", \"timestamp_raw\"])\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data = dataset.data # Do NOT sort again (keep original timestamp sort)\n",
    "preprocessed_data = []\n",
    "for group, data in preproc_data.groupby(\"station\"):\n",
    "    preprocessed_data.append(data)\n",
    "preprocessed_data = pd.concat(preprocessed_data)\n",
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_outliers = preprocessed_data[preprocessed_data[\"station\"] == \"Aotizhongxin\"][\"outlier\"]\n",
    "windows_outliers = windows_outliers.rolling(dataset.seq_len, step=dataset.stride, closed=\"left\").sum()[2:]\n",
    "windows_outliers = np.where(windows_outliers >= 1, 1, 0) # Rolling in pd starts with the n-1 prior rows (unintuitive)\n",
    "windows_outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = dataset.samples\n",
    "print(len(samples))\n",
    "\n",
    "targets = dataset.targets\n",
    "print(len(targets))\n",
    "\n",
    "print(preprocessed_data.shape[0]/dataset.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_keys = list(dataset.vocab.token2id.keys())\n",
    "for k in vocab_keys:\n",
    "    print(f\"\\n--{k}--\")\n",
    "    # pprint(dataset.vocab.token2id[k])\n",
    "    print(len(dataset.vocab.token2id[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.vocab.token2id[\"SPECIAL\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_id(windows_outliers, sample_id):\n",
    "    \"\"\"\n",
    "    Find the starting index in the the original data\n",
    "    that corresponds to a given dataset sample ID,\n",
    "    accoutning for detected outliers when buildind the dataset\n",
    "    \"\"\"\n",
    "    noutliers_included =  windows_outliers[:sample_id+1].sum()\n",
    "    next_safe_sample = 0\n",
    "    noutliers_additional = 0\n",
    "    if noutliers_included >= 1:\n",
    "        noutliers_additional = 0\n",
    "        next_safe_sample = 0\n",
    "        i = 0\n",
    "        while next_safe_sample < noutliers_included:\n",
    "            if windows_outliers[sample_id+1+i] == 1:\n",
    "                noutliers_additional += 1\n",
    "                i += 1\n",
    "            else:\n",
    "                next_safe_sample += 1\n",
    "    final_id = sample_id + noutliers_included + noutliers_additional\n",
    "\n",
    "    if windows_outliers[final_id] == 1: # is the final index an outlier as well\n",
    "        return final_id + get_final_id(windows_outliers[final_id:], 0)\n",
    "    else:\n",
    "        return final_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 38 # Only works for samples of the first station (because the rolling windows for outliers is NOT grouped by station first)\n",
    "stride = dataset.stride\n",
    "final_id = get_final_id(windows_outliers, sample_id)\n",
    "raw_sample = raw_data[stride * final_id: dataset.seq_len + stride * final_id]\n",
    "preprocessed_sample = preprocessed_data[stride * final_id: dataset.seq_len + stride * final_id]\n",
    "pytorch_sample = torch.tensor(samples[sample_id]).reshape(dataset.seq_len, -1)\n",
    "pytorch_target = torch.tensor(targets[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sample_above_pm(min_pm: float, samples: list, targets: list, seq_len: int=10, n:int=1):\n",
    "    pm = 0\n",
    "    i = -1\n",
    "    occur = 0\n",
    "    while ((pm < min_pm) or (occur < n)):\n",
    "        i += 1\n",
    "        target = torch.tensor(targets[i])\n",
    "        pm = target.max()\n",
    "        if pm >= min_pm:\n",
    "            occur += 1\n",
    "    return (\n",
    "        i,\n",
    "        torch.tensor(samples[i]).reshape(seq_len, -1),\n",
    "        torch.tensor(targets[i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_sample_above_pm(min_pm=600, samples=samples, targets=targets, seq_len=10, n=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats on targets\n",
    "preprocessed_data_wo_meas_outliers = preprocessed_data[preprocessed_data[\"PM10\"] >= preprocessed_data[\"PM2.5\"]].copy(deep=True) # Measurement error otherwise (removed from pytorch samples)\n",
    "preprocessed_data_wo_meas_outliers[[\"PM2.5\", \"PM10\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of targets and comparisons of transformations\n",
    "\n",
    "fig, axes = plt.subplots(nrows=7, ncols=2, figsize=(12, 10))\n",
    "sns.violinplot(\n",
    "    ax=axes[0][0],\n",
    "    x='PM2.5', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=preprocessed_data_wo_meas_outliers[\"PM2.5\"].min(),\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[0][1],\n",
    "    x='PM10', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    cut=preprocessed_data_wo_meas_outliers[\"PM10\"].min(),\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "preprocessed_data_wo_meas_outliers[[\"PM2.5_minmaxscaled\", \"PM10_minmaxscaled\"]] = minmax_scaler.fit_transform(preprocessed_data_wo_meas_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[1][0],\n",
    "    x='PM2.5_minmaxscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[1][1],\n",
    "    x='PM10_minmaxscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "preprocessed_data_wo_meas_outliers[[\"PM2.5_robustscaled\", \"PM10_robustscaled\"]] = robust_scaler.fit_transform(preprocessed_data_wo_meas_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[2][0],\n",
    "    x='PM2.5_robustscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[2][1],\n",
    "    x='PM10_robustscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "quantile_scaler = QuantileTransformer(output_distribution=\"normal\")\n",
    "preprocessed_data_wo_meas_outliers[[\"PM2.5_quantilescaled\", \"PM10_quantilescaled\"]] = quantile_scaler.fit_transform(preprocessed_data_wo_meas_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[3][0],\n",
    "    x='PM2.5_quantilescaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[3][1],\n",
    "    x='PM10_quantilescaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "uniform_scaler = QuantileTransformer(output_distribution=\"uniform\")\n",
    "preprocessed_data_wo_meas_outliers[[\"PM2.5_uniformscaled\", \"PM10_uniformscaled\"]] = uniform_scaler.fit_transform(preprocessed_data_wo_meas_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[4][0],\n",
    "    x='PM2.5_uniformscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[4][1],\n",
    "    x='PM10_uniformscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "preprocessed_data_wo_meas_outliers[\"PM2.5_logscaled\"] = preprocessed_data_wo_meas_outliers[\"PM2.5\"].map(lambda x: np.log(x))\n",
    "preprocessed_data_wo_meas_outliers[\"PM10_logscaled\"] = preprocessed_data_wo_meas_outliers[\"PM10\"].map(lambda x: np.log(x))\n",
    "sns.violinplot(\n",
    "    ax=axes[5][0],\n",
    "    x='PM2.5_logscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[5][1],\n",
    "    x='PM10_logscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "preprocessed_data_wo_meas_outliers[[\"PM2.5_stdscaled\", \"PM10_stdscaled\"]] = std_scaler.fit_transform(preprocessed_data_wo_meas_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[6][0],\n",
    "    x='PM2.5_stdscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[6][1],\n",
    "    x='PM10_stdscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_meas_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Targets distributions (after removing measurements outliers)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways:\n",
    "# - Targets distributions are right-skewed, lots of outliers\n",
    "# - We use StdScaler for the targets (and with no activation in the last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispersion targets outliers\n",
    "\n",
    "def get_IQR_outlier_cutoff(df, column, iqr_scalar=1.5):\n",
    "\n",
    "     Q1 = df[column].quantile(0.25)\n",
    "     Q3 = df[column].quantile(0.75)\n",
    "     IQR = Q3 - Q1\n",
    "     lower_outliers_cutoff = (Q1 - iqr_scalar * IQR)\n",
    "     higher_outliers_cutoff = (Q3 + iqr_scalar * IQR)\n",
    "     return (lower_outliers_cutoff, higher_outliers_cutoff)\n",
    "\n",
    "lower_outliers_cutoff_pm25, higher_outliers_cutoff_pm25 = get_IQR_outlier_cutoff(preprocessed_data_wo_meas_outliers, \"PM2.5\")\n",
    "print(f\"{lower_outliers_cutoff_pm25=}\") \n",
    "print(f\"{higher_outliers_cutoff_pm25=}\")\n",
    "\n",
    "lower_outliers_cutoff_pm10, higher_outliers_cutoff_pm10 = get_IQR_outlier_cutoff(preprocessed_data_wo_meas_outliers, \"PM10\")\n",
    "print(f\"{lower_outliers_cutoff_pm10=}\") \n",
    "print(f\"{higher_outliers_cutoff_pm10=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of *outlier* targets and comparisons of transformations\n",
    "\n",
    "preprocessed_data_wo_disp_outliers = preprocessed_data_wo_meas_outliers[\n",
    "    (preprocessed_data_wo_meas_outliers[\"PM2.5\"] <= higher_outliers_cutoff_pm25) &\n",
    "    (preprocessed_data_wo_meas_outliers[\"PM10\"] <= higher_outliers_cutoff_pm10)\n",
    "].copy(deep=True)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=7, ncols=2, figsize=(12, 10))\n",
    "sns.violinplot(\n",
    "    ax=axes[0][0],\n",
    "    x='PM2.5', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    cut=preprocessed_data_wo_disp_outliers[\"PM2.5\"].min(),\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[0][1],\n",
    "    x='PM10', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    cut=preprocessed_data_wo_disp_outliers[\"PM10\"].min(),\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "preprocessed_data_wo_disp_outliers[[\"PM2.5_minmaxscaled\", \"PM10_minmaxscaled\"]] = minmax_scaler.fit_transform(preprocessed_data_wo_disp_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[1][0],\n",
    "    x='PM2.5_minmaxscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[1][1],\n",
    "    x='PM10_minmaxscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "preprocessed_data_wo_disp_outliers[[\"PM2.5_robustscaled\", \"PM10_robustscaled\"]] = robust_scaler.fit_transform(preprocessed_data_wo_disp_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[2][0],\n",
    "    x='PM2.5_robustscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[2][1],\n",
    "    x='PM10_robustscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "quantile_scaler = QuantileTransformer(output_distribution=\"normal\")\n",
    "preprocessed_data_wo_disp_outliers[[\"PM2.5_quantilescaled\", \"PM10_quantilescaled\"]] = quantile_scaler.fit_transform(preprocessed_data_wo_disp_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[3][0],\n",
    "    x='PM2.5_quantilescaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[3][1],\n",
    "    x='PM10_quantilescaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "uniform_scaler = QuantileTransformer(output_distribution=\"uniform\")\n",
    "preprocessed_data_wo_disp_outliers[[\"PM2.5_uniformscaled\", \"PM10_uniformscaled\"]] = uniform_scaler.fit_transform(preprocessed_data_wo_disp_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[4][0],\n",
    "    x='PM2.5_uniformscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[4][1],\n",
    "    x='PM10_uniformscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=0,\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "preprocessed_data_wo_disp_outliers[\"PM2.5_logscaled\"] = preprocessed_data_wo_disp_outliers[\"PM2.5\"].map(lambda x: np.log(x))\n",
    "preprocessed_data_wo_disp_outliers[\"PM10_logscaled\"] = preprocessed_data_wo_disp_outliers[\"PM10\"].map(lambda x: np.log(x))\n",
    "sns.violinplot(\n",
    "    ax=axes[5][0],\n",
    "    x='PM2.5_logscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[5][1],\n",
    "    x='PM10_logscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "preprocessed_data_wo_disp_outliers[[\"PM2.5_stdscaled\", \"PM10_stdscaled\"]] = std_scaler.fit_transform(preprocessed_data_wo_disp_outliers[[\"PM2.5\", \"PM10\"]] )\n",
    "sns.violinplot(\n",
    "    ax=axes[6][0],\n",
    "    x='PM2.5_stdscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[6][1],\n",
    "    x='PM10_stdscaled', \n",
    "    split=True,\n",
    "    data=preprocessed_data_wo_disp_outliers,\n",
    "    inner=\"quart\",\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Preprocessed targets distributions (after removing dispersion outliers, based on 1.5 IQR)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways:\n",
    "# - Targets (without dispersion outliers) are still right-skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of *outlier* targets and comparisons of transformations\n",
    "\n",
    "outliers = preprocessed_data_wo_meas_outliers[\n",
    "    (preprocessed_data_wo_meas_outliers[\"PM2.5\"] > higher_outliers_cutoff_pm25) |\n",
    "    (preprocessed_data_wo_meas_outliers[\"PM10\"] > higher_outliers_cutoff_pm10)\n",
    "].copy(deep=True)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 2))\n",
    "sns.violinplot(\n",
    "    ax=axes[0],\n",
    "    x='PM2.5', \n",
    "    split=True,\n",
    "    data=outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=preprocessed_data_wo_meas_outliers[\"PM2.5\"].min(),\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[1],\n",
    "    x='PM10', \n",
    "    split=True,\n",
    "    data=outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=preprocessed_data_wo_meas_outliers[\"PM10\"].min(),\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Preprocessed outliers targets distributions (outliers based on 1.5 IQR)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways:\n",
    "# - Outlier targets are also right skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispersion targets extreme outliers\n",
    "\n",
    "extreme_lower_outliers_cutoff_pm25, extreme_higher_outliers_cutoff_pm25 = get_IQR_outlier_cutoff(preprocessed_data_wo_meas_outliers, \"PM2.5\", 2.5)\n",
    "print(f\"{extreme_lower_outliers_cutoff_pm25=}\") \n",
    "print(f\"{extreme_higher_outliers_cutoff_pm25=}\")\n",
    "\n",
    "extreme_lower_outliers_cutoff_pm10, extreme_higher_outliers_cutoff_pm10 = get_IQR_outlier_cutoff(preprocessed_data_wo_meas_outliers, \"PM10\",2.5)\n",
    "print(f\"{extreme_lower_outliers_cutoff_pm10=}\") \n",
    "print(f\"{extreme_higher_outliers_cutoff_pm10=}\")\n",
    "\n",
    "extreme_outliers = preprocessed_data_wo_meas_outliers[\n",
    "    (preprocessed_data_wo_meas_outliers[\"PM2.5\"] > extreme_higher_outliers_cutoff_pm25) |\n",
    "    (preprocessed_data_wo_meas_outliers[\"PM10\"] > extreme_higher_outliers_cutoff_pm10)\n",
    "].copy(deep=True)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 2))\n",
    "sns.violinplot(\n",
    "    ax=axes[0],\n",
    "    x='PM2.5', \n",
    "    split=True,\n",
    "    data=extreme_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=preprocessed_data_wo_meas_outliers[\"PM2.5\"].min(),\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "sns.violinplot(\n",
    "    ax=axes[1],\n",
    "    x='PM10', \n",
    "    split=True,\n",
    "    data=extreme_outliers,\n",
    "    inner=\"quart\",\n",
    "    cut=preprocessed_data_wo_meas_outliers[\"PM10\"].min(),\n",
    "    bw_adjust=.1,\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Preprocessed extreme outliers targets distributions (outliers based on 2.5 IQR)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways:\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of pollution over the years\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12, 8))\n",
    "sns.lineplot(\n",
    "    ax=ax1,\n",
    "    x='year_month', \n",
    "    y='PM2.5', \n",
    "    hue='station', \n",
    "    data=raw_data\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=ax2,\n",
    "    x='year_month', \n",
    "    y='PM10', \n",
    "    hue='station', \n",
    "    data=raw_data\n",
    ")\n",
    "ax1.legend(loc='upper left', ncol=6)\n",
    "ax2.get_legend().remove()\n",
    "ax1.tick_params(axis='x', labelrotation=70)\n",
    "ax2.tick_params(axis='x', labelrotation=70)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways: \n",
    "# - year and month are important. \n",
    "# - PM2.5 and PM10 follow the same trends\n",
    "# - station name matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of pollution by day of the month\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    ax=ax1,\n",
    "    x='day', \n",
    "    y='PM2.5', \n",
    "    hue='station', \n",
    "    data=raw_data\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=ax2,\n",
    "    x='day', \n",
    "    y='PM10', \n",
    "    hue='station', \n",
    "    data=raw_data\n",
    ")\n",
    "ax1.legend(loc='upper left', ncol=6)\n",
    "ax2.get_legend().remove()\n",
    "ax1.tick_params(axis='x', labelrotation=70)\n",
    "ax2.tick_params(axis='x', labelrotation=70)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways: \n",
    "# - day of the month matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of pollution by weekday\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
    "sns.boxplot(\n",
    "    ax=ax1,\n",
    "    x='station', \n",
    "    y='PM2.5', \n",
    "    hue='weekday', \n",
    "    data=raw_data\n",
    ")\n",
    "sns.boxplot(\n",
    "    ax=ax2,\n",
    "    x='station', \n",
    "    y='PM10', \n",
    "    hue='weekday', \n",
    "    data=raw_data\n",
    ")\n",
    "ax1.legend(loc='upper left', ncol=7)\n",
    "ax2.get_legend().remove()\n",
    "ax1.tick_params(axis='x', labelrotation=0)\n",
    "ax2.tick_params(axis='x', labelrotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways: \n",
    "# - day of the week matters a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in pollution levels (PM10 < PM2.5)\n",
    "n_hard_outliers = raw_data[raw_data[\"PM10\"] < raw_data[\"PM2.5\"]].shape[0]\n",
    "print(n_hard_outliers / raw_data.shape[0])\n",
    "\n",
    "# Take away:\n",
    "# 4% of samples are inconsistent outliers (PM2.5 are included in PM10)\n",
    "# cf. https://aqicn.org/faq/2013-02-02/why-is-pm25-often-higher-than-pm10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of pollution by hour of the day\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12, 4))\n",
    "sns.lineplot(\n",
    "    ax=ax1,\n",
    "    x='hour', \n",
    "    y='PM2.5', \n",
    "    hue='station', \n",
    "    data=raw_data\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=ax2,\n",
    "    x='hour', \n",
    "    y='PM10', \n",
    "    hue='station', \n",
    "    data=raw_data\n",
    ")\n",
    "ax1.legend(loc='upper left', ncol=6)\n",
    "ax2.get_legend().remove()\n",
    "ax1.tick_params(axis='x', labelrotation=0)\n",
    "ax2.tick_params(axis='x', labelrotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take aways: \n",
    "# - hour of the day matters, differs by the station name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "\n",
    "sns.pairplot(\n",
    "    raw_data,\n",
    "    kind=\"reg\", \n",
    "    # kind=\"scatter\", \n",
    "    y_vars=[\"PM2.5\", \"PM10\"], \n",
    "    x_vars=['SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN','WSPM'],\n",
    "    # hue=\"station\",\n",
    "    plot_kws={\n",
    "        'line_kws':{'color':'red'}, \n",
    "        'scatter_kws': {'alpha': 0.1}\n",
    "        # 'alpha': 0.25\n",
    "    }\n",
    ")\n",
    "\n",
    "# Take away:\n",
    "# - NO2 and CO correlate well with PM concentration (should be salient in attention maps)\n",
    "# - Maybe some outliers clusters in NO2, CO and O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of raw vs. preprocessed numerical features\n",
    "\n",
    "num_features = ['SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN','WSPM']\n",
    "fig, axes = plt.subplots(nrows=len(num_features), ncols=2, figsize=(16, 10))\n",
    "\n",
    "for i, f in enumerate(num_features):\n",
    "    sns.histplot(\n",
    "        ax=axes[i][0],\n",
    "        stat=\"percent\",\n",
    "        x=f, \n",
    "        data=raw_data\n",
    "    )\n",
    "    # sns.stripplot(\n",
    "    sns.histplot(\n",
    "        ax=axes[i][1],\n",
    "        stat=\"percent\",\n",
    "        x=f, \n",
    "        data=preprocessed_data\n",
    "    )\n",
    "plt.tight_layout()\n",
    "\n",
    "# Take away:\n",
    "# - need to compare various encoding schemes for numerical variables, e.g., \n",
    "# - Gorishniy et al.\n",
    "# - Binning (quantization, decision-tree leaf, hand-made)\n",
    "# - SAX + anchor (e.g., mean or starting value)\n",
    "# - TabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From TabBERT\n",
    "def _quantization_binning(nbins, data):\n",
    "    qtls = np.arange(0.0, 1.0 + 1 / nbins, 1 / nbins)\n",
    "    bin_edges = np.quantile(data, qtls, axis=0)\n",
    "    bin_widths = np.diff(bin_edges, axis=0)\n",
    "    bin_centers = bin_edges[:-1] + bin_widths / 2\n",
    "    return bin_edges, bin_centers, bin_widths\n",
    "\n",
    "def _quantize(nbins, inputs, bin_edges):\n",
    "    quant_inputs = np.zeros(inputs.shape[0])\n",
    "    for i, x in enumerate(inputs):\n",
    "        quant_inputs[i] = np.digitize(x, bin_edges)\n",
    "    quant_inputs = quant_inputs.clip(1, nbins) - 1\n",
    "    return quant_inputs\n",
    "\n",
    "# sns.histplot(raw_data[\"RAIN\"], binwidth=1)\n",
    "t = raw_data[[\"RAIN\", \"hour\"]].groupby(\"RAIN\").count()\n",
    "print(t)\n",
    "\n",
    "# From KBinsDiscretizer\n",
    "kbd = KBinsDiscretizer(n_bins=50, strategy=\"uniform\", encode=\"ordinal\", subsample=None)\n",
    "test = kbd.fit_transform(raw_data[\"RAIN\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "print(kbd.bin_edges_)\n",
    "print(np.unique(test.squeeze(1), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind direction (wd) categorical variable data exploration\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12, 4))\n",
    "sns.catplot(\n",
    "    x='wd', \n",
    "    y='PM2.5', \n",
    "    # hue='station', \n",
    "    kind=\"swarm\",\n",
    "    data=raw_data.sample(10_000), # takes too long otherwise\n",
    "    s=2,\n",
    ")\n",
    "sns.catplot(\n",
    "    x='wd', \n",
    "    y='PM10', \n",
    "    # hue='station', \n",
    "    kind=\"swarm\",\n",
    "    data=raw_data.sample(10_000),\n",
    "    s=2,\n",
    ")\n",
    "\n",
    "# Take-away:\n",
    "# - WD alone does not seem very informative about the targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
