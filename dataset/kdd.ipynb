{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from copy import deepcopy\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/home/razorin/tabularts/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataset.kdd import KDDDataset\n",
    "from dataset.vocab import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = None\n",
    "timedelta_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"TabBERT\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_representation = \"as int\"\n",
    "quantize_num_cols = True\n",
    "n_bins = 50\n",
    "add_step_sep_token = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path_pretrain = '/mnt/storage/raphael/pkdd99/pkdd99_pretraining_post-encoding.csv'\n",
    "load_path_finetune = '/mnt/storage/raphael/pkdd99/pkdd99_finetuning_post-encoding.csv'\n",
    "\n",
    "seq_len = 150 # NB: this is `t_max` in the UniTTab paper.\n",
    "min_frequency = 0.\n",
    "grouping_col = \"account_id\"\n",
    "ts_col = \"timestamp\"\n",
    "ordered_cols = [\"amount_trans\", \"balance\", \"k_symbol\", \"operation\", \"type_trans\", \"Year\", \"Month\", \"Day\", \"weekday\"]\n",
    "init_categorical_indicator = [False, False, True, True, True, True, True, True, True]\n",
    "delta_features = [\n",
    "    {\n",
    "        \"name\": \"delta_days\",\n",
    "        \"unit\": \"timedelta64[D]\",\n",
    "    },\n",
    "]\n",
    "label_col = \"status\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1042740, 10)\n",
      "(54694, 11)\n",
      "(1097434, 11)\n"
     ]
    }
   ],
   "source": [
    "raw_df_pt = pd.read_csv(load_path_pretrain, nrows=nrows)\n",
    "raw_df_pt[\"pretraining\"] = 1\n",
    "print(raw_df_pt.shape)\n",
    "df_pt = raw_df_pt.copy(deep=True)\n",
    "\n",
    "raw_df_ft = pd.read_csv(load_path_finetune, nrows=nrows)\n",
    "raw_df_ft[\"pretraining\"] = 0\n",
    "print(raw_df_ft.shape)\n",
    "df_ft = raw_df_ft.copy(deep=True)\n",
    "\n",
    "raw_df = pd.concat([raw_df_pt, raw_df_ft])\n",
    "print(raw_df.shape)\n",
    "df = raw_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle timestamp representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ts_col] = \"19\" + df[\"Year\"].astype(str) + \"-\" + df[\"Month\"].astype(str) + \"-\" + df[\"Day\"].astype(str)\n",
    "df[ts_col] = pd.to_datetime(df[ts_col], format=\"%Y-%m-%d\")\n",
    "df[\"date\"] = df[ts_col]\n",
    "df['weekday'] = df['date'].dt.dayofweek\n",
    "df = df.drop(columns=[\"date\"])\n",
    "\n",
    "if \"as int\" == ts_representation:\n",
    "    df[f\"{ts_col}_int\"] = df[ts_col].astype(int)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df[f\"{ts_col}_int\"] = min_max_scaler.fit_transform(df[f\"{ts_col}_int\"].to_numpy().reshape(-1, 1))\n",
    "    ordered_cols += [f\"{ts_col}_int\"]\n",
    "    init_categorical_indicator += [False]\n",
    "\n",
    "if \"as int and delta\" == ts_representation:\n",
    "    timedelta_suffix = \"_timedelta\"\n",
    "    \n",
    "    df[f\"{ts_col}_int\"] = df[ts_col].astype(int)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df[f\"{ts_col}_int\"] = min_max_scaler.fit_transform(df[f\"{ts_col}_int\"].to_numpy().reshape(-1, 1))\n",
    "    df = df.drop(columns=[\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "    ordered_cols += [f\"{ts_col}_int\"]\n",
    "    init_categorical_indicator += [False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_trans\n",
      "balance\n",
      "timestamp_int\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/razorin/conda_envs/tabformer/lib/python3.8/site-packages/sklearn/preprocessing/_discretization.py:279: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if quantize_num_cols:\n",
    "    for i, (c, cat) in enumerate(zip(ordered_cols, init_categorical_indicator)):\n",
    "        if not cat and c not in [ts_col, \"timedelta\"]:\n",
    "            print(c)\n",
    "            quantizer = KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", strategy=\"quantile\", subsample=None)\n",
    "            df[c] = quantizer.fit_transform(df[c].to_numpy().reshape(-1, 1))\n",
    "            init_categorical_indicator[i] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if min_frequency > 0:\n",
    "    for col, cat in zip(ordered_cols, init_categorical_indicator):\n",
    "        if cat and col not in [\"timedelta\"]:\n",
    "            print(col)\n",
    "            series = df[col].value_counts()\n",
    "            series_pct = (series / series.sum())\n",
    "            infrequent_mask = series_pct < min_frequency\n",
    "            # Replace infrequent categories by -1 \n",
    "            df[col] = np.where(\n",
    "                df[col].isin(series[infrequent_mask].index), \n",
    "                -1,\n",
    "                df[col]\n",
    "            )\n",
    "            print(f\"Nb of affected rows: {df[df[col] == -1].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories ordinal encoding from 1 to n_category.\n",
    "It was already done (but starting at 0 instead of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_trans\n",
      "balance\n",
      "k_symbol\n",
      "operation\n",
      "type_trans\n",
      "Year\n",
      "Month\n",
      "Day\n",
      "weekday\n",
      "timestamp_int\n"
     ]
    }
   ],
   "source": [
    "N_SPECIAL_TOKENS = 7\n",
    "vocab_start = 0\n",
    "for col, cat in zip(ordered_cols, init_categorical_indicator):\n",
    "    if cat:\n",
    "        print(col)\n",
    "        ordinal_enc = OrdinalEncoder()\n",
    "        col_values = df[col].to_numpy().reshape(-1, 1).astype(str)\n",
    "        df[col] = ordinal_enc.fit_transform(col_values)\n",
    "        df[col] = df[col] + N_SPECIAL_TOKENS + vocab_start # Common vocab\n",
    "        vocab_start = vocab_start + len(ordinal_enc.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>amount_trans</th>\n",
       "      <th>balance</th>\n",
       "      <th>k_symbol</th>\n",
       "      <th>operation</th>\n",
       "      <th>type_trans</th>\n",
       "      <th>pretraining</th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>timestamp_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2378</td>\n",
       "      <td>136.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>171.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576</td>\n",
       "      <td>136.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>171.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704</td>\n",
       "      <td>136.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>171.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3818</td>\n",
       "      <td>136.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>171.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972</td>\n",
       "      <td>147.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-02</td>\n",
       "      <td>172.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2632</td>\n",
       "      <td>147.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-02</td>\n",
       "      <td>172.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1539</td>\n",
       "      <td>158.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-03</td>\n",
       "      <td>173.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2484</td>\n",
       "      <td>158.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-03</td>\n",
       "      <td>173.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1695</td>\n",
       "      <td>158.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-03</td>\n",
       "      <td>173.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>793</td>\n",
       "      <td>158.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-03</td>\n",
       "      <td>173.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id    Day  Month   Year  amount_trans  balance  k_symbol  \\\n",
       "0        2378  136.0  124.0  118.0          12.0     51.0     103.0   \n",
       "1         576  136.0  124.0  118.0          13.0     51.0     103.0   \n",
       "2         704  136.0  124.0  118.0          13.0     51.0     103.0   \n",
       "3        3818  136.0  124.0  118.0          11.0     51.0     103.0   \n",
       "4        1972  147.0  124.0  118.0          10.0     51.0     103.0   \n",
       "5        2632  147.0  124.0  118.0          14.0     51.0     103.0   \n",
       "6        1539  158.0  124.0  118.0          11.0     51.0     103.0   \n",
       "7        2484  158.0  124.0  118.0          14.0     51.0     103.0   \n",
       "8        1695  158.0  124.0  118.0          50.0     51.0     103.0   \n",
       "9         793  158.0  124.0  118.0          12.0     51.0     103.0   \n",
       "\n",
       "   operation  type_trans  pretraining  status  timestamp  weekday  \\\n",
       "0      112.0       115.0            1     NaN 1993-01-01    171.0   \n",
       "1      112.0       115.0            1     NaN 1993-01-01    171.0   \n",
       "2      112.0       115.0            1     NaN 1993-01-01    171.0   \n",
       "3      112.0       115.0            1     NaN 1993-01-01    171.0   \n",
       "4      112.0       115.0            1     NaN 1993-01-02    172.0   \n",
       "5      112.0       115.0            1     NaN 1993-01-02    172.0   \n",
       "6      112.0       115.0            1     NaN 1993-01-03    173.0   \n",
       "7      112.0       115.0            1     NaN 1993-01-03    173.0   \n",
       "8      112.0       115.0            1     NaN 1993-01-03    173.0   \n",
       "9      112.0       115.0            1     NaN 1993-01-03    173.0   \n",
       "\n",
       "   timestamp_int  \n",
       "0          174.0  \n",
       "1          174.0  \n",
       "2          174.0  \n",
       "3          174.0  \n",
       "4          174.0  \n",
       "5          174.0  \n",
       "6          174.0  \n",
       "7          174.0  \n",
       "8          174.0  \n",
       "9          174.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243.87422222222222"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the average number of transactions per client\n",
    "df.groupby(\"account_id\").count()[\"Day\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the max number of transactions per client\n",
    "max_len = df.groupby(\"account_id\").count()[\"Day\"].max()\n",
    "max_len\n",
    "\n",
    "# Take the maximum length from now on\n",
    "seq_len = max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make sequential dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary() \n",
    "\n",
    "file_name = '/home/razorin/tabularts/data/kdd/vocab.nb'\n",
    "vocab.filename = file_name\n",
    "\n",
    "if \"delta\" in ts_representation:\n",
    "    vocab.timedelta_colid = 6 # Last ordered col will be timedelta\n",
    "\n",
    "vocab.set_field_keys([c for c in ordered_cols if c != \"timedelta\"])\n",
    "all_vocab = []\n",
    "for col in ordered_cols:\n",
    "    if col != \"timedelta\":\n",
    "        tokens = df[col].drop_duplicates().tolist()\n",
    "        for t in tokens:\n",
    "            vocab.set_id(t, col, return_local=False)\n",
    "\n",
    "vocab.save_vocab(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df_pt = df[df[\"pretraining\"] == 1]\n",
    "seq_df_pt = seq_df_pt.sort_values(ts_col).groupby(grouping_col).head(seq_len)\n",
    "if \"delta\" in ts_representation:\n",
    "    seq_df_pt = seq_df_pt[ordered_cols + [ts_col, grouping_col]]\n",
    "else:\n",
    "    seq_df_pt = seq_df_pt[ordered_cols + [grouping_col]]\n",
    "\n",
    "dataset_pt = []\n",
    "labels_pt = []\n",
    "for idx, group in seq_df_pt.groupby(grouping_col):\n",
    "\n",
    "    if \"delta\" in ts_representation:\n",
    "        group[\"timedelta\"] = group[ts_col]\n",
    "        ts_init = group[0:1][ts_col].values[0]\n",
    "        group[\"timedelta\"] = (group[\"timedelta\"] - ts_init).dt.days\n",
    "        dataset_pt.append(group[ordered_cols + [\"timedelta\"]].values)\n",
    "        ncols = group[ordered_cols + [\"timedelta\"]].shape[1]\n",
    "\n",
    "    else:\n",
    "        dataset_pt.append(group[ordered_cols].values)\n",
    "        ncols = group[ordered_cols].shape[1]\n",
    "        \n",
    "    labels_pt.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_trans     False\n",
       "balance          False\n",
       "k_symbol         False\n",
       "operation        False\n",
       "type_trans       False\n",
       "Year             False\n",
       "Month            False\n",
       "Day              False\n",
       "weekday          False\n",
       "timestamp_int    False\n",
       "account_id       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df_pt.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd_pt = KDDDataset(samples=dataset_pt, targets=labels_pt, vocab=vocab, ncols=ncols, seq_len=seq_len, data=seq_df_pt, data_root=load_path_pretrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning dataset (all transactions -> Last tmax handled by data collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df_ft = df[df[\"pretraining\"] == 0]\n",
    "seq_df_ft = seq_df_ft.sort_values(ts_col).groupby(grouping_col).head(seq_len)\n",
    "if \"delta\" in ts_representation:\n",
    "    seq_df_ft = seq_df_ft[ordered_cols + [ts_col, grouping_col, label_col]]\n",
    "else:\n",
    "    seq_df_ft = seq_df_ft[ordered_cols + [grouping_col, label_col]]\n",
    "\n",
    "dataset_ft = []\n",
    "labels_ft = []\n",
    "for idx, group in seq_df_ft.groupby(grouping_col):\n",
    "\n",
    "    if \"delta\" in ts_representation:\n",
    "        group[\"timedelta\"] = group[ts_col]\n",
    "        ts_init = group[0:1][ts_col].values[0]\n",
    "        group[\"timedelta\"] = (group[\"timedelta\"] - ts_init).dt.days\n",
    "        dataset_ft.append(group[ordered_cols + [\"timedelta\"]].values)\n",
    "        ncols = group[ordered_cols + [\"timedelta\"]].shape[1]\n",
    "\n",
    "    else:\n",
    "        dataset_ft.append(group[ordered_cols].values)\n",
    "        ncols = group[ordered_cols].shape[1]\n",
    "        \n",
    "    labels_ft.append(group[label_col].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_trans     False\n",
       "balance          False\n",
       "k_symbol         False\n",
       "operation        False\n",
       "type_trans       False\n",
       "Year             False\n",
       "Month            False\n",
       "Day              False\n",
       "weekday          False\n",
       "timestamp_int    False\n",
       "account_id       False\n",
       "status           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df_ft.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd_ft = KDDDataset(samples=dataset_ft, targets=labels_ft, vocab=vocab, ncols=ncols, seq_len=seq_len, data=seq_df_ft, data_root=load_path_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11143695014662756"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([l for l in labels_ft if l == 1]) / len(labels_ft) # ~11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning dataset (tmax random transactions) -> Increase dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = 10\n",
    "stride = tmax\n",
    "\n",
    "seq_df_ft_rand = df[df[\"pretraining\"] == 0]\n",
    "seq_df_ft_rand = seq_df_ft_rand.sort_values(ts_col).groupby(grouping_col).head(seq_len)\n",
    "if \"delta\" in ts_representation:\n",
    "    seq_df_ft_rand = seq_df_ft_rand[ordered_cols + [ts_col, grouping_col, label_col]]\n",
    "else:\n",
    "    seq_df_ft_rand = seq_df_ft_rand[ordered_cols + [grouping_col, label_col]]\n",
    "\n",
    "dataset_ft_rand = []\n",
    "labels_ft_rand = []\n",
    "for idx, group in seq_df_ft_rand.groupby(grouping_col):\n",
    "    \n",
    "    if group[ordered_cols].shape[0] < tmax:\n",
    "        dataset_ft_rand.append(group[ordered_cols].values[-tmax:])\n",
    "        labels_ft_rand.append(group[label_col].values[-1])\n",
    "    else:\n",
    "        max_len = group[ordered_cols].shape[0]\n",
    "        ncols = group[ordered_cols].shape[1]\n",
    "        n_examples = int(group[ordered_cols].shape[0] / tmax)\n",
    "        for i in range(n_examples):\n",
    "            dataset_ft_rand.append(group[ordered_cols][max_len-(i+1)*stride: max_len-i*stride].values)\n",
    "            labels_ft_rand.append(group[label_col].values[-1])\n",
    "assert len(labels_ft_rand) == len(dataset_ft_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd_ft_rand = KDDDataset(samples=dataset_ft_rand, targets=labels_ft_rand, vocab=vocab, ncols=ncols, seq_len=seq_len, data=seq_df_ft, data_root=load_path_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09746664088184104"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([l for l in labels_ft_rand if l == 1]) / len(labels_ft_rand) # ~10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5171"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_ft_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedelta_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_pt = f\"/home/razorin/tabularts/data/kdd/KDDDataset_pt{timedelta_suffix}.pkl\"\n",
    "\n",
    "with open(save_path_pt, \"wb\") as f:\n",
    "    pickle.dump(kdd_pt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_ft = f\"/home/razorin/tabularts/data/kdd/KDDDataset_ft{timedelta_suffix}.pkl\"\n",
    "\n",
    "with open(save_path_ft, \"wb\") as f:\n",
    "    pickle.dump(kdd_ft, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_ft = f\"/home/razorin/tabularts/data/kdd/KDDDataset_ft_rand{tmax}{timedelta_suffix}.pkl\"\n",
    "\n",
    "with open(save_path_ft, \"wb\") as f:\n",
    "    pickle.dump(kdd_ft_rand, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
